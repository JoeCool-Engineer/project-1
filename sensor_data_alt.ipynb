{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Randomly selected rows with a sample size of 3 looks like this:\\n\", str(row_mean))\\nprint(\"\\n\")\\nprint(\"The sum of selected sensor values:\\n\", str(row_select.sum(axis=0)))\\nprint(\"\\n\")\\nprint(\"The mean of selected sensor values:\\n\", str(row_select.mean(axis=0)))\\nprint(\"\\n\")\\n#print(\"The covariance of selected sensor values using the built in covariance function:\\n\", str(row_select.cov()))\\nprint(row_mean)\\nprint(\"\\n\")\\nprint(\"The covariance of selected sensor values using the equation 1:\\n\", str(sample_covariance))\\n\\npd.plotting.scatter_matrix(df, marker=\\'o\\', range_padding=0.35)\\n\\nplt.show()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries and notes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "#import csv\n",
    "#from scipy import stats\n",
    "#from typing import Tuple, Optional\n",
    "\n",
    "filename = 'datasets/sensor_readings.csv'\n",
    "#df = pd.read_csv(filename)\n",
    "#df.shape\n",
    "#df.info(memory_usage='deep') #memory usage: 78.3 KB\n",
    "#df.columns \n",
    "\"\"\"\n",
    "Index(['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5',\n",
    "       'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10'],\n",
    "      dtype='object')\n",
    "\"\"\"\n",
    "\n",
    "#We can select the columns we want to use by their name\n",
    "#df = pd.read_csv(filename, usecols=['feature_1', 'feature_4', 'feature_10'])\n",
    "#df.shape\n",
    "#df.info(memory_usage='deep') #memory usage: 23.6 KB\n",
    "\n",
    "#Alternatively we can select the columns we want to use by their index\n",
    "df = pd.read_csv(filename) #usecols=[0, 1, 3, 6, 9] property to select columns by index\n",
    "#We can also select the rows we want to use by their index\n",
    "#row_select = df.loc[[1, 2, 6, 8]]\n",
    "#Creates the mean of the selected rows for calculating the covariance and to center the data\n",
    "#row_mean = row_select.mean(axis=0)  # To create a new list with mean values .to_list()\n",
    "\n",
    "#center_df = df - df.mean()\n",
    "#centered_data = row_select.sub(row_mean, axis=1)\n",
    "#df.info(memory_usage='deep') #memory usage: 23.6 KB\n",
    "#sample_covariance = centered_data.cov()\n",
    "\n",
    "\"\"\"\n",
    "print(\"Randomly selected rows with a sample size of 3 looks like this:\\n\", str(row_mean))\n",
    "print(\"\\n\")\n",
    "print(\"The sum of selected sensor values:\\n\", str(row_select.sum(axis=0)))\n",
    "print(\"\\n\")\n",
    "print(\"The mean of selected sensor values:\\n\", str(row_select.mean(axis=0)))\n",
    "print(\"\\n\")\n",
    "#print(\"The covariance of selected sensor values using the built in covariance function:\\n\", str(row_select.cov()))\n",
    "print(row_mean)\n",
    "print(\"\\n\")\n",
    "print(\"The covariance of selected sensor values using the equation 1:\\n\", str(sample_covariance))\n",
    "\n",
    "pd.plotting.scatter_matrix(df, marker='o', range_padding=0.35)\n",
    "\n",
    "plt.show()\n",
    "\"\"\"\n",
    "#sum_values = row_index.sum()\n",
    "#num_values = len(row_index)\n",
    "#mean_values = row_index.mean()\n",
    "#print(\"The number of values in the first row is: \", num_values)\n",
    "#print(\"The sum of the values in the first row is: \", sum_values)\n",
    "#print(\"The mean of the values in the first row is: \", mean_values)\n",
    "#print(row_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1 (Alternate): Covariance Estimation and Analysis\n",
    "**Due: Should be finished by 2/11/2025**\n",
    "\n",
    "## Overview\n",
    "In this milestone, you will implement and analyze covariance estimation from data, building directly on the concepts from Lessons 9 (Random Vectors) and 10 (Covariance Matrices). \n",
    "\n",
    "Choose one of the provided datasets:\n",
    "1. Stock Returns (`stock_returns.csv`)\n",
    "2. Sensor Readings (`sensor_readings.csv`)\n",
    "3. Image Features (`image_features.csv`)\n",
    "\n",
    "## Learning Objectives\n",
    "1. Implement and validate covariance estimation from data\n",
    "2. Understand the critical role of centering in covariance estimation\n",
    "3. Visualize and interpret covariance structures\n",
    "4. Analyze how centering affects statistical properties\n",
    "\n",
    "## Required Deliverables\n",
    "\n",
    "### 1. Implementation (40%)\n",
    "\n",
    "#### Covariance Estimation\n",
    "This function implements the core statistical concept of covariance estimation:\n",
    "- Input: Matrix X where each row is an observation and each column is a variable\n",
    "- Output: Square matrix showing relationships between all pairs of variables\n",
    "- Key steps:\n",
    "  1. Center the data (optional but important)\n",
    "  2. Compute pairwise relationships\n",
    "  3. Ensure result is symmetric\n",
    "\n",
    "First starting with calculating the Covariance of the sample data using:\n",
    "\n",
    "\\begin{equation} \n",
    "s_{xy} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{n-1} \\tag 1\n",
    "\\end{equation}\n",
    "\n",
    "Note: The following will answers will not use the Population Covariance unless specified within the problem statement. \n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{xy} = \\frac{\\sum (x_i - \\sigma_x)(y_i - \\sigma_y)}{n} \\tag 2\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix using .to_numpy():\n",
      " [[ 7.38466580e-03  4.76842422e-03 -8.86350647e-01  1.23490010e+01\n",
      "  -1.76304016e+02]\n",
      " [ 3.88578605e-03  6.93691925e-02  4.90554117e-02  9.60958152e+00\n",
      "   3.21697806e+01]\n",
      " [-2.38932099e-03 -1.02071072e-02  9.68392284e-01  3.58774335e+01\n",
      "  -4.31620313e+01]\n",
      " [-7.18832388e-03  2.07302154e-02  5.50041694e-02  5.67146224e+01\n",
      "   9.85449686e+01]\n",
      " [ 5.72006278e-03 -1.96094873e-02 -2.67336233e-01 -1.39564653e+01\n",
      "  -3.05619111e+01]]\n",
      "Type: <class 'numpy.ndarray'>\n",
      "The Covariance Matrix: \n",
      " [[ 5.82487498e+03 -2.11501539e+03  7.04681798e+02 -4.73609739e+03\n",
      "   3.21556000e+02]\n",
      " [-2.11501539e+03  8.12521051e+02 -3.11734917e+02  1.61855140e+03\n",
      "  -4.32214095e+00]\n",
      " [ 7.04681798e+02 -3.11734917e+02  1.55442486e+02 -4.46405951e+02\n",
      "  -1.01983416e+02]\n",
      " [-4.73609739e+03  1.61855140e+03 -4.46405951e+02  4.08071999e+03\n",
      "  -5.16768044e+02]\n",
      " [ 3.21556000e+02 -4.32214095e+00 -1.01983416e+02 -5.16768044e+02\n",
      "   3.01517601e+02]]\n",
      "The covariance matrix of the selected sensor values is:\n",
      "             feature_1  feature_2  feature_5    feature_9    feature_10\n",
      "feature_1    0.000037  -0.000007  -0.002618    -0.148460     -0.445028\n",
      "feature_2   -0.000007   0.001227  -0.000817     0.124980      1.506479\n",
      "feature_5   -0.002618  -0.000817   0.449745     8.188563     31.924928\n",
      "feature_9   -0.148460   0.124980   8.188563   729.881475   1249.834100\n",
      "feature_10  -0.445028   1.506479  31.924928  1249.834100  10444.743627\n",
      "The correlation matrix of the selected sensor values is:\n",
      "             feature_1  feature_2  feature_5  feature_9  feature_10\n",
      "feature_1    1.000000  -0.033326  -0.640219  -0.901150   -0.714087\n",
      "feature_2   -0.033326   1.000000  -0.034789   0.132080    0.420861\n",
      "feature_5   -0.640219  -0.034789   1.000000   0.451958    0.465798\n",
      "feature_9   -0.901150   0.132080   0.451958   1.000000    0.452665\n",
      "feature_10  -0.714087   0.420861   0.465798   0.452665    1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\npairplot = sns.pairplot(df_centered)        \\n        \\nfor i, j in zip(*np.triu_indices_from(pairplot.axes, 1)):\\n    ax_centered = pairplot.axes[i, j]\\n    # Add vertical line at mean of x-axis\\n    ax_centered.axvline(selected_mean[j], color='r', linestyle='--')\\n    # Add horizontal line at mean of y-axis \\n    #ax_centered.axhline(means_centered[i], color='r', linestyle='--')\\n  \""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Returns:\n",
    "        Covariance matrix (n_features, n_features)\n",
    "        \n",
    "    Notes:\n",
    "        Centering is crucial for covariance estimation because:\n",
    "        1. Removes mean offset that would bias correlation estimates\n",
    "        2. Makes results interpretable as variance around the mean\n",
    "        3. Ensures positive semidefinite property of result\n",
    "    \"\"\"\n",
    "    # TODO: Implement covariance estimation\n",
    "    # Hints:\n",
    "    # - Review Lesson 10 for covariance matrix definition\n",
    "    # - Look up numpy's mean() function parameters\n",
    "    # - Think about matrix multiplication with transpose\n",
    "    # - Consider how to verify your result is symmetric\n",
    "\n",
    "def rand_cols(features, min_value, max_value):\n",
    "    if max_value - min_value + 1 < features:\n",
    "        raise ValueError('The number of features exceeds the range of values')\n",
    "    return random.sample(range(min_value, max_value + 1), features)\n",
    "\n",
    "def random_rows(length, min_value, max_value):\n",
    "    if max_value - min_value + 1 < length:\n",
    "        raise ValueError('The number of rows exceeds the range of values')\n",
    "    return random.sample(range(min_value, max_value + 1), length)\n",
    "\n",
    "def calc_cov_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Calculates the covariance matrix of a given matrix.\n",
    "\n",
    "    Args:\n",
    "        matrix (numpy.ndarray): A 2D numpy array representing the data matrix,\n",
    "                                where rows are variables and columns are observations.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The covariance matrix of the input matrix.\n",
    "    \"\"\"\n",
    "    # Calculate the mean of each row (variable)\n",
    "    mean_rows = np.mean(matrix, axis=0, keepdims=True)\n",
    "\n",
    "    # Center the data by subtracting the mean of each row\n",
    "    centered_data = matrix - mean_rows\n",
    "\n",
    "    # Calculate the covariance matrix\n",
    "    n_observations = matrix.shape[1]\n",
    "    covariance_matrix = (centered_data @ centered_data.T) / (n_observations - 1)\n",
    "\n",
    "    return covariance_matrix\n",
    "\n",
    "# Generate random list of integers for selecting columns (sample size)\n",
    "n_features = 5\n",
    "min_feature = 0\n",
    "max_feature = 9\n",
    "\n",
    "# Generate random list of integers for selecting rows (sample size)\n",
    "n_samples = 5\n",
    "minimum_value = 0\n",
    "maximum_value = 999\n",
    "\n",
    "select_col = rand_cols(n_features, min_feature, max_feature)\n",
    "sort_col = sorted(select_col)\n",
    "sensor_df = pd.read_csv(filename, usecols=sort_col)\n",
    "mean_data = sensor_df.mean()\n",
    "\n",
    "#row_index = np_array[random_integer_list] #Select random rows\n",
    "\n",
    "#Use the code below to calculate the covariance and create matrix\n",
    "#centered_data = sensor_df - mean_data\n",
    "\n",
    "#print(mean_data[sort_col[9]])\n",
    "\"\"\" \n",
    "for i in range(len(sort_col)):\n",
    "    for j in range(len(sensor_df)):\n",
    "        #print(f\"Column {sensor_df.columns[i]} row {j} is {sensor_df[sensor_df.columns[i]][j]}. Centered value is {sensor_df[sensor_df.columns[i]][j] - mean_data[sort_col[i]]}\")\n",
    "        center_df = sensor_df[sensor_df.columns[i]][j] - mean_data[sort_col[i]]\n",
    "        #print(f\"Column {sensor_df.columns[i]} row {j} is {sensor_df[sensor_df.columns[i]][j]}. Centered value is {center_df}\")\n",
    "\"\"\"\n",
    "\n",
    "# Generate random list of integers\n",
    "random_integer_list = random_rows(n_samples, minimum_value, maximum_value) \n",
    "row_sorted = sorted(random_integer_list)\n",
    "        \n",
    "selected_rows = sensor_df.iloc[row_sorted]\n",
    "\n",
    "#Create a new dataframe with the selected rows\n",
    "s_df = pd.DataFrame(selected_rows)\n",
    "#Save the sample dataframe to a csv file\n",
    "s_df.to_csv('datasets/sample_data.csv', index=False)\n",
    "\n",
    "#Read from new CSV file\n",
    "s_filename = 'datasets/sample_data.csv'\n",
    "sample_df = pd.read_csv(s_filename)\n",
    "\n",
    "sample_mean = sample_df.select_dtypes(include='number').mean()\n",
    "df_centered = sample_df.select_dtypes(include='number') - sample_mean\n",
    "\n",
    "# Using .to_numpy() to create matrix\n",
    "matrix_numpy = sample_df.to_numpy()\n",
    "print(\"Matrix using .to_numpy():\\n\", matrix_numpy)\n",
    "print(\"Type:\", type(matrix_numpy))\n",
    "\n",
    "covariance_matrix = calc_cov_matrix(matrix_numpy)\n",
    "print(\"The Covariance Matrix: \\n\", covariance_matrix)\n",
    "\n",
    "#cov_matrix = centered_data.cov()\n",
    "print(\"The covariance matrix of the selected sensor values is:\\n\", df_centered.cov())\n",
    "\n",
    "#The correlation matrix is calculated using the corr() function\n",
    "print(\"The correlation matrix of the selected sensor values is:\\n\", df_centered.corr())\n",
    "\n",
    "\"\"\" \n",
    "pairplot = sns.pairplot(df_centered)        \n",
    "        \n",
    "for i, j in zip(*np.triu_indices_from(pairplot.axes, 1)):\n",
    "    ax_centered = pairplot.axes[i, j]\n",
    "    # Add vertical line at mean of x-axis\n",
    "    ax_centered.axvline(selected_mean[j], color='r', linestyle='--')\n",
    "    # Add horizontal line at mean of y-axis \n",
    "    #ax_centered.axhline(means_centered[i], color='r', linestyle='--')\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimator Comparison\n",
    "\n",
    "This function validates your implementation against numpy's trusted version:\n",
    "\n",
    "- Compare your results with numpy.cov()\n",
    "- Check for numerical differences\n",
    "- Understand any discrepancies\n",
    "- Good software engineering practice: test against known good implementation\n",
    "- It's ok if they are not exactly the same, but they should be close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_estimators(X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compare your estimator to numpy's implementation\n",
    "    \n",
    "    Args:\n",
    "        X: Data matrix\n",
    "        \n",
    "    Returns:\n",
    "        Your covariance matrix, numpy's covariance matrix\n",
    "    \"\"\"\n",
    "    # TODO: Compare your implementation to np.cov()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Size Analysis\n",
    "\n",
    "This function explores how many samples we need for reliable estimates:\n",
    "\n",
    "- Try different sample sizes (small to large)\n",
    "- Sampling means to draw samples from the dataset and compute only on the smaller sample\n",
    "- See how estimates stabilize\n",
    "- Important for real applications where data is limited\n",
    "- Helps understand estimation uncertainty\n",
    "- Advanced (repeatedly sample at the same sample size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sample_size(X: np.ndarray,\n",
    "                       sizes: Optional[np.ndarray] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze how covariance estimate changes with sample size\n",
    "\n",
    "    Args:\n",
    "        X: Full dataset\n",
    "        sizes: Array of sample sizes to test\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results\n",
    "    \"\"\"\n",
    "    if sizes is None:\n",
    "        sizes = np.logspace(1, np.log10(len(X)), 20).astype(int)\n",
    "    \n",
    "    # TODO: For each size n:\n",
    "    # 1. Sample n points randomly\n",
    "    # 2. Compute covariance\n",
    "    # 3. Track how estimate changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analysis (40%)\n",
    "\n",
    "#### Sample Size Effects\n",
    "\n",
    "- Plot how covariance estimates converge as n increases\n",
    "    - Hint: Plot Frobenius norm of difference between successive estimates\n",
    "        - Frobenius norm is the sum of the squares of the elements of the matrix\n",
    "        - You can use np.linalg.norm(A, ord='fro') to compute the Frobenius norm\n",
    "    - Try logarithmic spacing of sample sizes\n",
    "    - Look for where the curve flattens out\n",
    "- Identify minimum sample size needed for stable estimates\n",
    "    - Look for where changes between successive estimates become small\n",
    "    - Consider setting a threshold (e.g., < 1% change)\n",
    "    - Think about your application's accuracy needs\n",
    "- Compare your results with numpy's implementation\n",
    "    - Use np.allclose() with reasonable tolerance\n",
    "    - Remember: Small numerical differences are normal\n",
    "    - Focus on pattern similarity rather than exact matches\n",
    "\n",
    "#### Visualization and Interpretation\n",
    "\n",
    "- Create covariance heatmaps\n",
    "- Plot confidence ellipses\n",
    "- Interpret the meaning of:\n",
    "    - Diagonal elements\n",
    "    - Off-diagonal elements\n",
    "    - Positive vs negative covariance\n",
    "\n",
    "#### Understanding Data Preprocessing\n",
    "\n",
    "- Centering Analysis:\n",
    "    - Compare covariance with/without centering\n",
    "    - Visualize how centering affects the data cloud\n",
    "    - Prove mathematically why centering is necessary (optional)\n",
    "- Basic Scaling Introduction:\n",
    "    - Scaling means to divide each variable (column) by its standard deviation\n",
    "    - Compare raw vs standardized variables\n",
    "    - Show when different scales cause problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Advanced Topics\n",
    "\n",
    "### Population vs Sample Statistics\n",
    "\n",
    "- Research the difference between population and sample statistics\n",
    "- Investigate why numpy.cov() uses (n-1) denominator by default\n",
    "- Compare with scipy.stats covariance functions\n",
    "- Experiment with different denominators (n vs n-1)\n",
    "- Consider when each might be appropriate\n",
    "\n",
    "Example exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimate_covariance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compare different covariance implementations\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Your implementation\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m cov_yours \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_covariance\u001b[49m(X)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# NumPy implementation (uses n-1)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m cov_numpy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcov(X\u001b[38;5;241m.\u001b[39mT)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'estimate_covariance' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare different covariance implementations\n",
    "\n",
    "# Your implementation\n",
    "cov_yours = estimate_covariance(X)\n",
    "\n",
    "# NumPy implementation (uses n-1)\n",
    "cov_numpy = np.cov(X.T)\n",
    "\n",
    "# Manual calculation with n denominator\n",
    "X_centered = X - X.mean(axis=0)\n",
    "cov_pop = (X_centered.T @ X_centered) / len(X)\n",
    "\n",
    "# Compare results and consider:\n",
    "# - When do the differences matter?\n",
    "# - Why might we prefer one over another?\n",
    "# - What assumptions are we making?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Used Formulas\n",
    "**Mean**\n",
    "\\begin{equation} \n",
    "\\bar{x} = \\frac{\\sum_x}{n} \\tag 1\n",
    "\\end{equation}\n",
    "**Variance**\n",
    "\\begin{equation} \n",
    "s^2_{x} = \\frac{\\sum (x_i - \\bar{x})^2}{n-1} \\tag 2\n",
    "\\end{equation}\n",
    "**Standard Deviation**\n",
    "\\begin{equation} \n",
    "s_{x} = \\sqrt{\\frac{\\sum (x_i - \\bar{x})^2}{n-1}} \\tag 3\n",
    "\\end{equation}\n",
    "**Covariance**\n",
    "\\begin{equation} \n",
    "s_{xy} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{n-1} \\tag4\n",
    "\\end{equation}\n",
    "**Correlation**\n",
    "\\begin{equation} \n",
    "r = \\frac{s_{xy}} {s_x s_y} \\frac{(Covariance)} {(Standard Deviation)}\\tag 5\n",
    "\\end{equation}\n",
    "Note: If equation below is true then a relationship exists.\n",
    "\\begin{equation}\n",
    "|r| \\ge \\frac{2}{\\sqrt{n}}\n",
    "\\end{equation}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
